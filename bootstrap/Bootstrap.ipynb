{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "\n",
    "\n",
    "![Bootstrap](https://raw.githubusercontent.com/SchattenGenie/pic-storage/master/bootstrap.png)\n",
    "\n",
    "\n",
    "\n",
    "### Lecture recap\n",
    "\n",
    "##### Параметрический и непараметрический бутстрап\n",
    "##### Оценки дисперсии функционалов\n",
    "\n",
    "Пусть есть выборка $X = \\{x_i\\}_{i=1}^{n}$, некоторый функционал $T_n(X)$ и мы хотим оценить дисперсию $V_F(T_n)$. Не зная истинного распределения это можно сделать с помощью непараметрического или параметрического бутстрапа.\n",
    "\n",
    "В непараметрическом бутстрапе оценка дисперсии делается следующим образом:\n",
    "\n",
    "  1. Рэсемплим выборку с возвращением B раз: $X_1^*, X_2^*, X_B^* \\sim X$\n",
    "  2. Вычисляем $T_1^*, ..., T_B^*$\n",
    "  3. $$V_F(T_n) \\approx v_{boot} = \\frac{1}{B - 1} \\sum\\limits_{b=1}^B \\left(T_b^* - \\bar{T}^*  \\right)^2$$\n",
    "  \n",
    "  \n",
    "Параметрический бутстрап отличается от непараметрического в первом шаге. Вместо сэмплирования из исходной выборки сэмплирование происходит из некоторого распределения, которое было найдено методом максимума правдоподобия по исходной выборке.\n",
    "\n",
    "##### Оценка доверительного интервала\n",
    "\n",
    "  1. $1 - 2 \\alpha$ центральный интервал:\n",
    "\n",
    "$$C_n = 2 T_n(X) - (T_b^*)^{(1 - \\alpha)}, 2 T_n(X) - (T_b^*)^{(\\alpha)}$$\n",
    "\n",
    "  2. $1 - 2 \\alpha$ нормальный интервал:\n",
    "\n",
    "$$C_n = T_n(X) - z_{\\alpha}v_{boot}, T_n(X) - z_{1 - \\alpha}v_{boot}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Предположим, что мы бутстрепом отобрали N событий из выборки состоящей из N наблюдений. \n",
    "  1. Какая вероятность что первый элемент бутстрепной выборки не k элемент оригинальной выборки?\n",
    "  2. Какая вероятность что k элемент оригинальной выборки не входит в бутстрепную выборку?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обоснование использование техники ресемплирования. Эффективность и состоятельность оценки плотности вероятности функцией $\\hat{F}(x) = \\frac{1}{N} \\sum\\limits_i I[x > x_i]$.\n",
    "\n",
    "$$E\\left[ \\hat{F}(x) \\right] = F(x)$$\n",
    "\n",
    "\n",
    "$$Var \\left[ \\hat{F}(x) \\right] = \\frac{F(x)(F(x) - 1)}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример построение CDF (Cumulative distribution function) с помощью бутстрепа для треугольного распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Треугольное распределение\n",
    "\n",
    "#### Плотность распределения:\n",
    "\n",
    "![Треугольное распределение](http://rdostudio.raox.ru/help/help/rdo_lang_rus/images/triangular_distribution/td_pdf.png)\n",
    "![График плотности распределения](http://rdostudio.raox.ru/help/help/rdo_lang_rus/images/triangular_distribution/td_pdf_graph.png)\n",
    "#### Функция распределения:\n",
    "![Функция распределения](http://rdostudio.raox.ru/help/help/rdo_lang_rus/images/triangular_distribution/td_cdf.png)\n",
    "![График функции распределения](http://rdostudio.raox.ru/help/help/rdo_lang_rus/images/triangular_distribution/td_cdf_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDF треугольного распределения с a = 0, b = 1, c = 2\n",
    "def TrueTriangularDistrubition(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    elif x < 1:\n",
    "        return x**2 / 2\n",
    "    elif x < 2:\n",
    "        return 2*x - x**2 / 2 - 1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# размер изначальной выборки\n",
    "N = 300\n",
    "# размер бутстрепной выборки\n",
    "B = 800\n",
    "\n",
    "X = np.random.uniform(0, 1, size=N) + np.random.uniform(0, 1, size=N)\n",
    "Xb = np.random.choice(X, (B, N), replace=True)\n",
    "Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 8))\n",
    "\n",
    "# CDF для каждого бутстрепной выборки\n",
    "for bootstrap_sample in Xb:\n",
    "    plt.hist(bootstrap_sample, bins=N, density=True, histtype='step',\n",
    "             cumulative=True, alpha = 0.1, color='grey', linewidth = 2)\n",
    "\n",
    "# Истинное CDF\n",
    "plt.plot(np.linspace(0, 2, 100), \n",
    "         list(map(TrueTriangularDistrubition, np.linspace(0, 2, 100))), \n",
    "         color = 'red', linewidth = 3, label='True CDF')    \n",
    "\n",
    "# \n",
    "plt.hist(X, bins=N, density=True, histtype='step',\n",
    "         cumulative=True, label='Bootstrap CDF', color='blue', linewidth = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость точности приближения распределений статистик бутстрепом\n",
    "\n",
    "Один интересный практический вопрос это как быстро сходится бутстреп. Достаточно ли 10000 испытаний, а 1000, а 100?\n",
    "\n",
    "В целом, чем больше тем лучше, но сейчас мы увидим, что даже для оценки CDF распределения верно что $B_k$ сходится к $B_{\\infty}$(значение статистики при бесконечном количестве ресемплов) как $\\frac{1}{\\sqrt{n}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# разбиение на бины\n",
    "bins = np.linspace(0, 2, N)\n",
    "\n",
    "# ground truth CDF\n",
    "true_distr = np.array(list(map(TrueTriangularDistrubition, np.linspace(0, 2, N - 1))))\n",
    "\n",
    "means = []\n",
    "\n",
    "# диапазон количества испытаний для которых будем смотреть на зависимость\n",
    "Bs = np.arange(1, 1000, 1)\n",
    "for B in tqdm(Bs):\n",
    "    # бутстрап выборки X B раз\n",
    "    Xb = np.random.choice(X, (B, N), replace=True)\n",
    "    cdfs = []\n",
    "    for bootstrap_sample in Xb:\n",
    "        # считаем разность CDF полученного бутстрапом и ground truth\n",
    "        cdfs.append(\n",
    "            true_distr - np.cumsum(np.histogram(bootstrap_sample, bins=bins)[0] / N)\n",
    "        )\n",
    "    # считаем среднее от разностей CDF\n",
    "    means.append(np.array(cdfs).mean(axis=0))\n",
    "    \n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "# считаем бегущую дисперсию, чтобы получить более гладкий график\n",
    "r = np.std(rolling_window(np.array(means).mean(axis=1), 15), -1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(Bs[:len(r)], r)\n",
    "plt.plot(Bs, 1e-2 / np.sqrt(Bs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике для оценки параметров рекомендуется использовать размер бутстрепной выборки порядка 100-1000, для интервальных оценок лучше делать >10000 испытаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение t-bootstrap интервалов и обычного  бутстреп\n",
    "\n",
    "Предположим, что у нас есть некоторая $\\theta = T(X)$, то с помощью бутстрапа мы можем сгенерировать новую, бутстрапную, выборку:\n",
    "\n",
    "$$\\{ \\hat{\\theta}_i \\}_{i=0}^{B}$$\n",
    "\n",
    "По этой выборке можно оценивать не только стандартную ошибку, но и доверительные интервалы. Мы сравним два подхода для подсчёта доверительных интервалов. \n",
    "\n",
    "Перцентильный интервал интуитивно легко понять. Для оценки доверительного интервала $1 - 2 \\alpha$ считается $\\alpha$-квантиль и $1 - \\alpha$-квантиль и объявляются верхней и нижней границами доверительного интервала, т.е.:\n",
    "\n",
    "$$C_n = \\left(\\hat{\\theta}^{(\\alpha)}, \\hat{\\theta}^{(1 - \\alpha)}\\right)$$\n",
    "\n",
    "Bootstrap-t оценивается по-другому:\n",
    "\n",
    "$$C_n = \\left( \\hat{\\theta} - \\hat{t}^{(1 - \\alpha)}, \\hat{\\theta} - \\hat{t}^{(\\alpha)} \\right),$$\n",
    "\n",
    "где квантили $t$ считаются от следующих оценок по бутстрапным выборкам:\n",
    "\n",
    "$$t^*(b) = \\frac{\\hat{\\theta}^*(b) - \\hat{\\theta}}{\\hat{se}^*(b)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import cauchy\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from scipy.stats import expon\n",
    "def mean(X):\n",
    "    return np.mean(X, axis=1)\n",
    "\n",
    "def mean_t(X, X_original):\n",
    "    return (np.mean(X, axis=1) - np.mean(X_original)) / np.std(X, axis=1)\n",
    "\n",
    "def percentile_confidence_interval(X, q=5):\n",
    "    return np.percentile(X, q=q / 2), np.percentile(X, q=100 - q / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistics(distr, limits_1, limits_2, limits_3, mean_val):\n",
    "    X = distr.rvs(size=N)\n",
    "    boots = np.random.choice(X, (B, N), replace=True)\n",
    "    mean_boots = mean(boots)\n",
    "    mean_boots_t = mean_t(boots, X)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 6))\n",
    "    fig.suptitle('{} distribution. N={}, B={}'.format(distr.dist.name, N, B))\n",
    "    axes[0].hist(X, bins=100, density=True, range=limits_1);\n",
    "    axes[0].axvline(x=mean_val, linewidth=4, color='r')\n",
    "    axes[0].set_xlim(limits_1)\n",
    "    # axes[0].legend()\n",
    "    axes[1].hist(mean_boots, bins=100, density=True, range=limits_2);\n",
    "    # axes[1].axvline(x=mean_val, linewidth=4, color='r')\n",
    "    lower_interval, higher_interval = percentile_confidence_interval(mean_boots)\n",
    "    axes[1].axvline(x=lower_interval, linewidth=1, \n",
    "                    color='r', linestyle='--')\n",
    "    axes[1].axvline(x=higher_interval, linewidth=1, \n",
    "                    color='r', linestyle='--', label='Percentile bootstrap interval')\n",
    "    lower_interval, higher_interval = percentile_confidence_interval(mean_boots_t)\n",
    "\n",
    "    axes[1].axvline(x=X.mean() - X.std() * higher_interval, linewidth=1, \n",
    "                    color='g', linestyle='-')\n",
    "    axes[1].axvline(x=X.mean() - X.std() * lower_interval, linewidth=1, \n",
    "                    color='g', linestyle='-', label='t-bootstrap interval')\n",
    "    axes[1].set_xlim(limits_2)\n",
    "    axes[1].legend()\n",
    "    \n",
    "    axes[2].hist(mean_boots_t, bins=100, density=True, range=limits_3);\n",
    "    # axes[2].axvline(x=0, linewidth=4, color='r')\n",
    "    lower_interval, higher_interval = percentile_confidence_interval(mean_boots_t)\n",
    "    axes[2].axvline(x=lower_interval, linewidth=1,\n",
    "                    color='r', linestyle='--')\n",
    "    axes[2].axvline(x=higher_interval, linewidth=1, \n",
    "                    color='r', linestyle='--', label='t-bootstrap interval')\n",
    "    axes[2].set_xlim(limits_3)\n",
    "    axes[2].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "B = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение Коши\n",
    "\n",
    "![распределение Коши](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plot_statistics(cauchy(), [-10, 10], [-5, 5], [-0.5, 0.5], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормальное распределение\n",
    "\n",
    "![Нормальное распределение](http://mcimeer.narod.ru/data/t1/img/clip_image032.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plot_statistics(norm(), [-10, 10], [-0.7, 0.7], [-0.4, 0.4], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Экспоненциальное распределение\n",
    "![экспоненциальное распределение](https://bourabai.ru/cm/img/03_11000.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 5 различных random seed для экспоненциального распределения\n",
    "for i in range(5):\n",
    "    plot_statistics(expon(), [0, 10], [1. - 0.7, 1. + 0.7], [-1, 1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В целом, перцентильный интервал выглядит самым простым вариантом оценивания, однако в реальности он даёт весьма плохие результаты так как __сильно__ зависит от того насколько хорошо изначальная выборка аппроксимирует истинное распределение случайной величины. Часто можно встретить советы что лучше __не используйте__ перцентильный бутстрап для оценки доверительных интервалов, однако, конечно, самое правильное решение это тестировать все доступные методы.\n",
    "\n",
    "У t-bootstrap есть одно интересное свойство, к примеру,: как можно было заметить на последнем примере с экспоненциальным распределением, интервалы t-bootstrap смещены влево. t-bootstrap \"уважает\" ассиметрию распределений при расчёте доверительных интервалов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интегрирование с помощью бутстрепа\n",
    "\n",
    "Интегрирование функции $$f(x) = x \\cos (71 x) + \\frac{\\sin (13 x^2)}{x}$$ на интервале $(0, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x * np.cos(71 * x) + np.sin(13 * x**2) / x\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "plt.plot(x, f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sample for integration\n",
    "n = 100\n",
    "x = f(np.random.random(n))\n",
    "\n",
    "# bootstrap MC integration\n",
    "reps = 1000\n",
    "xb = np.random.choice(x, (n, reps), replace=True)\n",
    "yb = 1 / np.arange(1, n+1)[:, None] * np.cumsum(xb, axis=0)\n",
    "upper, lower = np.percentile(yb, [2.5, 97.5], axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.plot(np.arange(1, n+1)[:, None], yb, c='grey', alpha=0.1)\n",
    "plt.plot(np.arange(1, n+1), yb[:, 0], c='red', linewidth=2)\n",
    "plt.plot(np.arange(1, n+1), upper, 'b', np.arange(1, n+1), lower, 'b', linewidth=2, label='95% interval');\n",
    "plt.axvline(21, 0, 1)\n",
    "plt.axvline(100, 0, 1)\n",
    "plt.axhline(0.762816332183, c='c', label='True integral value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap and jacknife bias estimatiom\n",
    "\n",
    "Посмотрим как можно оценивать смещение оценки с помощью бутстрепа и jacknife на трёх примерах:\n",
    "\n",
    "\n",
    "  * $x_i \\sim Exp(1)$, $\\theta = \\sigma^2$, $\\hat{\\theta} = \\frac{1}{N} \\sum (x_i - \\bar{x})^2$ -- смещённая оценка дисперсии. $\\hat{\\theta} = \\frac{1}{N - 1} \\sum (x_i - \\bar{x})^2$ -- несмещённая оценка.\n",
    "  * $x_i \\sim U(0, \\theta)$, $\\hat{\\theta} = \\max(x_i)$ -- смещённая оценка максимума равномерного распределения. $\\hat{\\theta} = \\frac{N + 1}{N}\\max(x_i)$ -- несмещённая оценка.\n",
    "  * $x_i \\sim U\\{0, \\theta\\}, \\theta \\in N$, $\\hat{\\theta} = \\max(x_i)$ -- смещённая оценка максимума равномерного дискретного распределения. $\\hat{\\theta} = \\frac{N + 1}{N} \\max(x_i) - 1$  -- несмещённая оценка.\n",
    "  \n",
    "  Зачем нужно уметь оценивать максимум дискретного распределения? Чтобы увидев на танке противника №60 дать состоятельную и несмещённую оценку общего числа танков ;)\n",
    "  \n",
    "  ![](https://upload.wikimedia.org/wikipedia/commons/6/61/Bundesarchiv_Bild_183-H26258%2C_Panzer_V_%22Panther%22.jpg)\n",
    "  \n",
    "  https://en.wikipedia.org/wiki/German_tank_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacknife\n",
    "\n",
    "Jacknife бутстрап строится на leave-one-out статистиках, т.е. статистиках посчитанных на всех измерениях кроме одного:\n",
    "\n",
    "$$\\hat{\\theta}_{(-i)} = \\theta(X_{(-i)})$$\n",
    "\n",
    "$$\\hat{\\theta}_{(\\cdot)} = \\frac{1}{N} \\sum\\limits_{i=1}^{N} \\hat{\\theta}_{(-i)}$$\n",
    "\n",
    "Для jacknife оценка дисперсии выглядит следующим образом:\n",
    "\n",
    "$$v_{jack} = \\frac{n-1}{n} \\sum\\limits_{i=1}^{n} \\left(\\hat{\\theta}_{(\\cdot)} - \\hat{\\theta}_{(-1)}\\right)^2$$\n",
    "\n",
    "\n",
    "#### Bias\n",
    "\n",
    "Смещение(bias) это разница между мат. ожиданием оценки статистики по сэмплу конечного размера и реальной величиной. \n",
    "\n",
    "$$bias_F = bias_F(\\hat{\\theta}, \\theta) = E_F[\\hat{\\theta}] - \\theta(F)$$\n",
    "\n",
    "Так как распределение $F$ нам неизвестно, то оценивать мы будем по бутстрапному распределению, т.е.:\n",
    "\n",
    "$$bias_{\\hat{F}} = bias_{\\hat{F}}(\\hat{\\theta}, \\theta) = E_{\\hat{F}}[\\hat{\\theta}^*] - \\theta(\\hat{F})$$\n",
    "\n",
    "#### Bootstrap bias & jacknife bias\n",
    "\n",
    "Для оценки смещения сравним обычный бутстреп и jacknife.\n",
    "\n",
    "Для бутстрепа смещение считается следующим образом(следует из формулы :\n",
    "\n",
    "$$\\hat{bias}_B = \\hat{\\theta}^* - \\hat{\\theta}$$\n",
    "\n",
    "Для jacknife смещение __определяется__ следующим образом:\n",
    "\n",
    "$$\\hat{bias}_{jack} = (n - 1) ( \\hat{\\theta}_{(\\cdot)} - \\hat{\\theta})$$\n",
    "\n",
    "\n",
    "#### Коррекция\n",
    "\n",
    "В общем случае коррекция делается следующим образом:\n",
    "\n",
    "$$\\bar{\\theta} = \\hat{\\theta} - \\hat{bias}$$\n",
    "\n",
    "Однако следует осознанно делать коррекцию, так как оценка смещения может иметь большую ошибку и тогда уменьшение смещения оценки будет __нивелировано__ возросшей дисперсией.\n",
    "\n",
    "https://arxiv.org/pdf/1709.06183.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Доказательство квадратичной точности jacknife bias estimation\n",
    "\n",
    "Для доказательства квадратичной точности оценки смещения jacknife сделаем одно простое предположение, что матожидание нашей статистики при ограниченном размере выборки раскладывается в ряд Тейлора от размера выборки:\n",
    "\n",
    "$$E_F \\hat{\\theta} = \\theta + \\frac{a_1(F)}{n-1} + \\frac{a_2(F)}{(n - 1)^2} + \\dots$$\n",
    "\n",
    "Подставим в формулу коррекции смещения jacknife оценку смещения:\n",
    "\n",
    "$$\\hat{\\theta} - \\hat{bias}_{jack} = \\hat{\\theta} - (n - 1) ( \\hat{\\theta}_{(\\cdot)} - \\hat{\\theta}) = n \\hat{\\theta} - (n - 1) \\hat{\\theta}_{(\\cdot)}$$\n",
    "\n",
    "Теперь возьмём от этого матожидание и разложим его по Тейлору:\n",
    "\n",
    "$$E_F \\left[ n \\hat{\\theta} - (n - 1) \\hat{\\theta}_{(\\cdot)} \\right] =  n\\left(\\theta + \\frac{a_1(F)}{n} + \\frac{a_2(F)}{n^2} + \\dots\\right) + $$\n",
    "\n",
    "$$ (n-1) \\left( \\theta + \\frac{a_1(F)}{n-1} + \\frac{a_2(F)}{(n-1)^2} + \\dots \\right) = $$\n",
    "\n",
    "$$ = \\theta - \\frac{a_2(F)}{n(n-1)} + o\\left(\\frac{1}{n^2}\\right)$$\n",
    "\n",
    "Как видно, jacknife избавляется от линейного члена в разложении смещения по размеру выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jackknife_resampling(data):\n",
    "    n = data.shape[0]\n",
    "    resamples = np.empty([n, n-1])\n",
    "    for i in range(n):\n",
    "        resamples[i] = np.delete(data, i)\n",
    "    return resamples\n",
    "\n",
    "\n",
    "def jackknife_stats(data, statistic):\n",
    "    from scipy.special import erfinv\n",
    "    n = data.shape[0]\n",
    "    resamples = jackknife_resampling(data)\n",
    "\n",
    "    stat_data = statistic(data)\n",
    "    jack_stat = np.apply_along_axis(statistic, 1, resamples)\n",
    "    mean_jack_stat = np.mean(jack_stat, axis=0)\n",
    "\n",
    "    bias = (n - 1) * (mean_jack_stat - stat_data)\n",
    "\n",
    "    estimate = stat_data - bias\n",
    "\n",
    "    return stat_data, bias, estimate\n",
    "\n",
    "def bootstrap_stats(X, statistic, B=1000):\n",
    "    boots = np.random.choice(X, (B, N), replace=True)\n",
    "    stat_data = np.mean(statistic(boots, axis=1))\n",
    "    bias = stat_data - statistic(X)\n",
    "    \n",
    "    estimate = statistic(X) - bias\n",
    "\n",
    "    return stat_data, bias, estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка $\\sigma^2$ для экспоненциального распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_comparison_sigma(N=10):\n",
    "    X = expon().rvs(N)\n",
    "    \n",
    "    true_bias = np.std(X) - np.std(X, ddof=1)\n",
    "    _, jack_bias, _ = jackknife_stats(X, statistic=np.std)\n",
    "\n",
    "    Bs = np.logspace(1, 3, 20).astype(int)\n",
    "    boot_biases = []\n",
    "    for B in Bs:\n",
    "        _, boot_bias, _ = bootstrap_stats(X, statistic=np.std, B=B)\n",
    "        boot_biases.append(boot_bias)\n",
    "        \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(Bs, boot_biases, label='Bootstrap bias')\n",
    "    plt.axhline(true_bias, c='g', label='True bias')\n",
    "    plt.axhline(jack_bias, c='r', label='Jacknife bias')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_bias_comparison_sigma(N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "def plot_bias_comparison_kurtosis(N=10):\n",
    "    X = expon().rvs(N)\n",
    "    \n",
    "    true_bias = kurtosis(X) - kurtosis(X, bias=False)\n",
    "    _, jack_bias, _ = jackknife_stats(X, statistic=kurtosis)\n",
    "\n",
    "    Bs = np.logspace(1, 3, 20).astype(int)\n",
    "    boot_biases = []\n",
    "    for B in Bs:\n",
    "        _, boot_bias, _ = bootstrap_stats(X, statistic=kurtosis, B=B)\n",
    "        boot_biases.append(boot_bias)\n",
    "        \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(Bs, boot_biases, label='Bootstrap bias')\n",
    "    plt.axhline(true_bias, c='g', label='True bias')\n",
    "    plt.axhline(jack_bias, c='r', label='Jacknife bias')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bias_comparison_kurtosis(N=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка $\\theta$ для $U[0, \\theta]$ и для $U\\{0, \\theta\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_comparison_sigma_uniform(N=10):\n",
    "    X = np.random.uniform(0, 1, N)\n",
    "    \n",
    "    true_bias = np.max(X) - np.max(X) * (len(X) + 1) / len(X)\n",
    "\n",
    "    _, jack_bias, _ = jackknife_stats(X, statistic=np.max)\n",
    "    boot_biases = []\n",
    "\n",
    "    Bs = np.logspace(1, 4, 20).astype(int)\n",
    "\n",
    "    for B in Bs:\n",
    "        _, boot_bias, _ = bootstrap_stats(X, statistic=np.max, B=B)\n",
    "        boot_biases.append(boot_bias)\n",
    "        \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(Bs, boot_biases, label='Bootstrap bias')\n",
    "    plt.axhline(true_bias, c='g', label='True bias')\n",
    "    plt.axhline(jack_bias, c='r', label='Jacknife bias')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bias_comparison_sigma_discrete(N=10, theta=100):\n",
    "    X = np.random.choice(np.arange(0, int(theta)), size=N, replace=True)\n",
    "    # X = np.random.choice(np.arange(0, int(theta)), size=N, replace=False)\n",
    "    true_bias = np.max(X) - (np.max(X) * (len(X) + 1) / len(X))\n",
    "\n",
    "    _, jack_bias, _ = jackknife_stats(X, statistic=np.max)\n",
    "    boot_biases = []\n",
    "\n",
    "    Bs = np.logspace(1, 4, 20).astype(int)\n",
    "\n",
    "    for B in Bs:\n",
    "        _, boot_bias, _ = bootstrap_stats(X, statistic=np.max, B=B)\n",
    "        boot_biases.append(boot_bias)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(Bs, boot_biases, label='Bootstrap bias')\n",
    "    plt.axhline(true_bias, c='g', label='True bias')\n",
    "    plt.axhline(jack_bias, c='r', label='Jacknife bias')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# запустите несколько раз\n",
    "plot_bias_comparison_sigma_uniform(N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# запустите несколько раз\n",
    "plot_bias_comparison_sigma_discrete(N=1000, theta=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Общее наблюдение\n",
    "\n",
    "Оценка смещения jacknife имеет более высокий порядок точности($o\\left(\\frac{1}{N^2}\\right)$) чем бутстрепная оценка($o\\left(\\frac{1}{N}\\right)$), что можно увидеть на примере оценки дисперсии и куртозис, поэтому имеет смысл в большинстве случаев использовать jacknife для оценки смещения.\n",
    "\n",
    "Однако, jacknife \"ломается\" на негладких статистиках: медиана, максимум, к примеру. В этом случае лучше использовать обычный bootstrap.\n",
    "\n",
    "? resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бутстреп временных рядов\n",
    "\n",
    "\n",
    "Бутстреп временных рядов обычно делают в два шага:\n",
    "\n",
    "  1. Обучают модель для предсказания временного ряда(авторегрессия, к примеру).\n",
    "  $$y_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 y_{t-2}$$\n",
    "  2. Запоминают остатки(residuals) от истинных значений и предсказанных:\n",
    "  $$\\hat{\\epsilon} = y_t - (\\beta_0 + \\beta_1 y_{t-1} + \\beta_2 y_{t-2})$$\n",
    "  3. Новые данные сэмплируют применяя обученную модель и добавляя к предсказанию случайно выбранное значение из residuals:\n",
    "  $$\\hat{y_t} = \\beta_0 + \\beta_1 \\hat{y}_{t-1} + \\beta_2 \\hat{y}_{t-2} + (\\epsilon \\sim \\hat{\\epsilon}) $$\n",
    "  \n",
    "  \n",
    "https://onlinecourses.science.psu.edu/stat501/node/358/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "clf = linear_model.LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regression_from_timeseries(X, n):\n",
    "    \"\"\"\n",
    "    X: 1D-numpy массив временных данных\n",
    "    n: количество сэмплов для предсказания\n",
    "    return: X, Y = [x_{t-n}, x_{t-n+1}, ..., x_{t-1}], x_{t}\n",
    "    \"\"\"\n",
    "    N = len(X)\n",
    "    x = np.zeros((N-n, n))\n",
    "    y = np.zeros((N-n, 1))\n",
    "\n",
    "    for i in range(N-n):\n",
    "        x[i,:] = X[i: i+n]\n",
    "        y[i] = X[i+n]\n",
    "\n",
    "    return x,y\n",
    "def bootstrap_timeseries(clf, xinit, residuals, N):\n",
    "    n = len(xinit)\n",
    "    bootstrap_sample = []\n",
    "    current_sample = xinit\n",
    "    for i in range(N):\n",
    "        new_dot = clf.predict([current_sample]).ravel()[0] + np.random.choice(residuals)\n",
    "        bootstrap_sample.append(new_dot)\n",
    "        current_sample = np.roll(current_sample, -1)\n",
    "        current_sample[-1] = new_dot\n",
    "    return bootstrap_sample\n",
    "\n",
    "n = 1 # авторегрессионный процесс первого порядка AR(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./goog.csv')['Close'].values[::-1][:600]\n",
    "\n",
    "data_mean = data.mean()\n",
    "data = data - data_mean\n",
    "# создаём обучающую выборку\n",
    "X, Y = make_regression_from_timeseries(data.ravel(), n)\n",
    "\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hat = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# остатки = реальные данные - предсказания модели\n",
    "residuals = Y.ravel() - clf.predict(X).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы хотим чтобы остатки были распределены по нормальному закону около нуля\n",
    "# это является индикатором что ошибки случайны и не коррелируют\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Residuals')\n",
    "plt.hist(residuals, bins=100);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# бутстрепом набираем выборку коэффициентов линейной регрессии\n",
    "beta_boots = []\n",
    "B = 100\n",
    "for i in tqdm(range(B)):\n",
    "    bootstraped_data = bootstrap_timeseries(clf, X[0, :], residuals, len(data))\n",
    "    X_boot, Y_boot = make_regression_from_timeseries(bootstraped_data, n)\n",
    "    beta_boots.append(clf.fit(X_boot, Y_boot).coef_)\n",
    "beta_boots = np.concatenate(beta_boots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Пример бутстрапа временного ряда')\n",
    "plt.plot(bootstraped_data + data_mean)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Исходный сэмпл')\n",
    "plt.plot(Y + data_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = beta_boots.shape[1]\n",
    "for k in range(K):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(\"{} коэффициент регрессии и бутстрепное распределение\".format(k + 1))\n",
    "    lower_interval, higher_interval = percentile_confidence_interval(beta_boots[:, k], q=5)\n",
    "    plt.hist(beta_boots[:, k], bins=50);\n",
    "    plt.axvline(x=beta_hat[0][k], linewidth=4, color='r', label='beta_{}'.format(k+1))\n",
    "    plt.axvline(x=lower_interval, linewidth=4, color='g', label='95% доверительный интервал'.format(k+1))\n",
    "    plt.axvline(x=higher_interval, linewidth=4, color='g')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы видите, для авторегрессии 1 порядка верно следующее:\n",
    "  * Измеренное значение лежит в 95% доверительном интервале\n",
    "  * Доверительный интервал достаточно далеко от 0\n",
    "  \n",
    "Второй факт означает следующее: если бы мы тестировали гипотезу о том равна ли $\\beta_1$ нулю, то с 95% вероятностью эта гипотеза отвергалась бы.\n",
    "\n",
    "Проверьте, верно ли это для AR(2)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
